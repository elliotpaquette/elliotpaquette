{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elliotpaquette/elliotpaquette/blob/master/ODE_resolvent_stuff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QScBz8TDwAyo"
      },
      "outputs": [],
      "source": [
        "def ode_resolvent_adaGrad(K, x, x_star, h, Dh, cov_grad_f, b, eta, ridge, times, label_noise,m):\n",
        "  \"\"\"Generate the theoretical solution to gradient flow\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  K : array (d x d)\n",
        "      covariance matrix\n",
        "  x, x_star : array (d x o)\n",
        "      initializations of x_0 and x_star\n",
        "  h : function (outputs scalar)\n",
        "    Computes the risk given C\n",
        "  Dh : function (outputs 2 matrices)\n",
        "        Computes for any time the derivatives $Dh_11$ and $Dh_{12}$ for $h(C(X)) = R(X)$\n",
        "  cov_grad_f : function (outputs 1 matrix)\n",
        "        Computes for any time the derivative of $E_a[\\nabla f(x) \\nabla f(x)^T]\n",
        "  b_0 : float\n",
        "        Constant in the denominator of adaGrad_norm\n",
        "  eta : float\n",
        "        Constant in the numerator of adaGrad_norm\n",
        "  ridge : float\n",
        "        The ridge parameter to pass\n",
        "  t_max : float\n",
        "      The number of epochs\n",
        "  n_grid : int\n",
        "      The number of grid points\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  t_grid: numpy.array(float)\n",
        "      the time steps used, which will discretize (0,t_max) into n_grid points\n",
        "  risks: numpy.array(float)\n",
        "      the values of the risk\n",
        "  \"\"\"\n",
        "\n",
        "  risks = np.zeros_like(times)\n",
        "  n_grid = jnp.shape(times)\n",
        "  n_grid = n_grid[0]\n",
        "\n",
        "  o = x.shape[1]\n",
        "  t = x_star.shape[1]\n",
        "  cross_terms = np.zeros((n_grid,o,t)) # times x o x t (same shape as C_12)\n",
        "  norm_terms = np.zeros((n_grid,o,o)) #times x o x o (same shape as C_11)\n",
        "  adaGrad_gammas =  np.zeros_like(times)\n",
        "\n",
        "  Dt = jnp.diff(times, prepend=times[0])\n",
        "\n",
        "  Keigs, Kvecs = jnp.linalg.eigh(K)\n",
        "  halfS_x = x.transpose()@Kvecs\n",
        "  halfS_x_star = x_star.transpose()@Kvecs\n",
        "\n",
        "\n",
        "  #K_squared = np.einsum('ij,jk->ik', K,K)\n",
        "  trace_K = jnp.sum(Keigs)\n",
        "  length_d = len(Keigs)\n",
        "\n",
        "  #S_12 is d x o x t\n",
        "  S_11 = jnp.einsum('ki,ji->ijk', halfS_x, halfS_x)\n",
        "  S_12 = jnp.einsum('ji,ki->ijk', halfS_x, halfS_x_star)\n",
        "  S_22 = jnp.einsum('ki,ji->ijk', halfS_x_star, halfS_x_star)\n",
        "\n",
        "  def adaGrad_gamma(eta, b, length_d, trace_K, risk, Dt):\n",
        "    integral_risk = jnp.sum( risk * Dt  )\n",
        "    #print(eta / jnp.sqrt( b**2 + ( 2.0 * trace_K) / length_d * integral_risk ))\n",
        "    return eta / jnp.sqrt( b**2 + ( 2.0 * trace_K) / length_d * integral_risk )\n",
        "\n",
        "  gamma = eta / b\n",
        "\n",
        "  for i in range(n_grid):\n",
        "    C_11 = jnp.tensordot(S_11, Keigs, axes=(0,0))\n",
        "    C_12 = jnp.tensordot(S_12, Keigs, axes=(0,0))\n",
        "    C_22 = jnp.tensordot(S_22, Keigs, axes=(0,0))\n",
        "\n",
        "  #DH_11 is o x o and DH_21 is t x o\n",
        "    DH_11, DH_21 = Dh(C_11, C_12, C_22, m)\n",
        "\n",
        "    #pdb.set_trace()\n",
        "    S_11_gr = -2.0*gamma*jnp.einsum('i,ijk->ijk', Keigs,(\n",
        "                                       jnp.tensordot(S_11,DH_11, axes=(2,0))\n",
        "                                       +jnp.tensordot(S_12,DH_21, axes=(2,0))\n",
        "                                       +jnp.einsum('ijk,jl->ilk', S_11, DH_11)\n",
        "                                       #+np.tensordot(S_11,DH_11, axes=(1,1))\n",
        "                                       +jnp.tensordot(S_12,DH_21, axes=(2,0))\n",
        "                                       )) - 2.0 * gamma * ridge * S_11\n",
        "\n",
        "    S_12_gr = -2.0*gamma*np.einsum('i,ijk->ikj', Keigs,(\n",
        "                                       jnp.tensordot(S_12,DH_11, axes=(1,0)) #output (d x t x o)\n",
        "                                       +jnp.tensordot(S_22,DH_21, axes=(1,0)) #output (d x t x o)\n",
        "\n",
        "                                       )) - 1.0 * gamma * ridge * S_12\n",
        "\n",
        "    S_11_noise = ( gamma**2/ float(d) )*jnp.tensordot(Keigs,cov_grad_f(C_11,C_12,C_22,label_noise),axes=0)\n",
        "\n",
        "    S_11 += Dt[i]*(S_11_gr + S_11_noise)\n",
        "    S_12 += Dt[i]*(S_12_gr)\n",
        "\n",
        "    risks[i] = h(C_11, C_12, C_22, label_noise)\n",
        "    adaGrad_gammas[i] = adaGrad_gamma(eta, b, length_d, trace_K, risks, Dt)\n",
        "    gamma = adaGrad_gammas[i]\n",
        "\n",
        "    cross_terms[i] = C_12\n",
        "\n",
        "    norm_terms[i] = C_11\n",
        "\n",
        "  return times, risks, cross_terms, norm_terms, adaGrad_gammas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions used to compute h, Dh and cov_grad_f, Dh = [D_11, D_21]\n",
        "\n",
        "def h(B11,B12,B22, label_noise):\n",
        "  return 0.5 * jnp.trace(B11) - 0.5 * jnp.trace(B12) - 0.5 * jnp.trace(B12.transpose()) + 0.5 *jnp.trace(B22) + 0.5 * jnp.sum( label_noise**2 )\n",
        "\n",
        "def Dh(C11,C21,C22, m):\n",
        "  Dh11 = 0.5 * jnp.identity( m )\n",
        "  Dh21 = -0.5 * jnp.identity( m )\n",
        "  return (Dh11, Dh21)\n",
        "\n",
        "def cov_grad_f(C11,C21,C22,label_noise):\n",
        "  cov_grad = C11 - C21 - C21.transpose() + C22 + jnp.einsum('i,j->ij', label_noise,label_noise)\n",
        "  return cov_grad\n"
      ],
      "metadata": {
        "id": "OzH85U8XwS2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b and eta are for adaGrad gammas - just change\n",
        "\n",
        "adaGrad_times, adaGrad_risks, adaGrad_cross_terms, adaGrad_norm_terms, adaGrad_gammas = ode_resolvent_adaGrad(K, jnp.reshape(initial, (d,phase_o)), jnp.reshape(strlin_xstar,(d,phase_t)),\n",
        "              h, Dh, cov_grad_f, b, eta, ridge, times, jnp.reshape(epsilon,(m,)), m)"
      ],
      "metadata": {
        "id": "VBZA9PaCwdqa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}